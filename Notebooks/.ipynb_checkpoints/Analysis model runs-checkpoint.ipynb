{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7497663a",
   "metadata": {},
   "source": [
    "# Analysis of top four models\n",
    "Inside this notebook we will delve furter into the top four models selected from all the model results, we will do an in-depth analysis on the feature importance, generalizability and the learning curve. All three sections can be ran individually after the imports below are ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7455e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f442c",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63198379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "gdf_zaanstad = gpd.read_file(\"../Data/dataset_zaanstad.gpkg\", layer=\"polluted_points\")\n",
    "gdf_oosterhout = gpd.read_file(\"../Data/dataset_oosterhout.gpkg\", layer=\"polluted_points\")\n",
    "\n",
    "# Exclude BOORPUNT_ID and geometry\n",
    "gdf_zaanstad = gdf_zaanstad.drop(columns=['BOORPUNT_ID', 'geometry'])\n",
    "gdf_oosterhout = gdf_oosterhout.drop(columns=['BOORPUNT_ID', 'geometry'])\n",
    "\n",
    "# Rename columns to English for the plot\n",
    "gdf_zaanstad = gdf_zaanstad.rename(columns={\"gewaspercelen\": \"Agricultural land\", \"oppervlaktewater\": \"Surface water\", \"wegen\":\"Roads\", \"spoorwegen\":\"Railroad\", \"industry\":\"Industry\", \"days_since_ref\":\"Date\"})\n",
    "gdf_oosterhout = gdf_oosterhout.rename(columns={\"gewaspercelen\": \"Agricultural land\", \"oppervlaktewater\": \"Surface water\", \"wegen\":\"Roads\", \"spoorwegen\":\"Railroad\", \"industry\":\"Industry\", \"days_since_ref\":\"Date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "def preprocess_data(data, use_bkk):\n",
    "    if not use_bkk:\n",
    "        data = data.drop(columns=['BKK'])\n",
    "    else:\n",
    "        bkk_mapping = {'AW_2000': 1, 'Wonen': 2, 'Industrie': 3}\n",
    "        data.replace({\"BKK\": bkk_mapping}, inplace=True)\n",
    "        data = data[data['BKK'] != 'Onbekend'].dropna()\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['TOETS_WBB'] = label_encoder.fit_transform(data['TOETS_WBB'])\n",
    "\n",
    "    X = data.drop(columns=['TOETS_WBB'])\n",
    "    y = data['TOETS_WBB']\n",
    "\n",
    "    # Columns to normalize\n",
    "    columns_to_normalize = ['Date', 'X', 'Y']\n",
    "    scaler = StandardScaler()\n",
    "    X[columns_to_normalize] = scaler.fit_transform(X[columns_to_normalize])\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess datasets\n",
    "X_train_oost, X_val_oost, y_train_oost, y_val_oost = preprocess_data(gdf_oosterhout, use_bkk=False)\n",
    "X_train_oost_bkk, X_val_oost_bkk, y_train_oost_bkk, y_val_oost_bkk = preprocess_data(gdf_oosterhout, use_bkk=True)\n",
    "X_train_zaan, X_val_zaan, y_train_zaan, y_val_zaan = preprocess_data(gdf_zaanstad, use_bkk=False)\n",
    "X_train_zaan_bkk, X_val_zaan_bkk, y_train_zaan_bkk, y_val_zaan_bkk = preprocess_data(gdf_zaanstad, use_bkk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and get feature importances\n",
    "def get_feature_importances(X_train, y_train, max_depth):\n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.feature_importances_\n",
    "\n",
    "# Train and extract feature importances for each scenario\n",
    "feature_importances_oost = get_feature_importances(X_train_oost, y_train_oost, 20)\n",
    "feature_importances_oost_bkk = get_feature_importances(X_train_oost_bkk, y_train_oost_bkk, 20)\n",
    "feature_importances_zaan = get_feature_importances(X_train_zaan, y_train_zaan, 30)\n",
    "feature_importances_zaan_bkk = get_feature_importances(X_train_zaan_bkk, y_train_zaan_bkk, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot feature importance\n",
    "def plot_feature_importance(importances, features, title, filename, figsize=(8, 4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.barplot(x=importances, y=features, palette=\"Blues_d\")\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Set the font size\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Plot and save feature importance for Oosterhout without BKK\n",
    "plot_feature_importance(\n",
    "    feature_importances_oost, \n",
    "    X_train_oost.columns, \n",
    "    'Oosterhout (without BKK)', \n",
    "    'feature_importances_oosterhout_without_bkk.png',\n",
    ")\n",
    "\n",
    "# Plot and save feature importance for Oosterhout with BKK\n",
    "plot_feature_importance(\n",
    "    feature_importances_oost_bkk, \n",
    "    X_train_oost_bkk.columns, \n",
    "    'Oosterhout (with BKK)', \n",
    "    'feature_importances_oosterhout_with_bkk.png',\n",
    ")\n",
    "\n",
    "# Plot and save feature importance for Zaanstad without BKK\n",
    "plot_feature_importance(\n",
    "    feature_importances_zaan, \n",
    "    X_train_zaan.columns, \n",
    "    'Zaanstad (without BKK)', \n",
    "    'feature_importances_zaanstad_without_bkk.png',\n",
    ")\n",
    "\n",
    "# Plot and save feature importance for Zaanstad with BKK\n",
    "plot_feature_importance(\n",
    "    feature_importances_zaan_bkk, \n",
    "    X_train_zaan_bkk.columns, \n",
    "    'Zaanstad (with BKK)', \n",
    "    'feature_importances_zaanstad_with_bkk.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44af4af",
   "metadata": {},
   "source": [
    "## Generalizability\n",
    "The second codeblock below can be used to choose which dataset should be the train dataset and which should be the test dataset. Additionally the baseline parameter can be set to True and False. If set to True the model will exclude the BKK as variable, if set to False it will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "gdf_zaanstad = gpd.read_file(\"../Data/dataset_zaanstad.gpkg\", layer=\"polluted_points\")\n",
    "gdf_oosterhout = gpd.read_file(\"../Data/dataset_oosterhout.gpkg\", layer=\"polluted_points\")\n",
    "\n",
    "# Exclude BOORPUNT_ID and geometry\n",
    "gdf_zaanstad = gdf_zaanstad.drop(columns=['BOORPUNT_ID', 'geometry'])\n",
    "gdf_oosterhout = gdf_oosterhout.drop(columns=['BOORPUNT_ID', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c663d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dataset\n",
    "dataset = gdf_oosterhout\n",
    "\n",
    "# Parameter to exclude the BKK\n",
    "baseline = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c07ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different param settings for different model runs\n",
    "max_depths = {\n",
    "    'Oosterhout_unbalance': 20,\n",
    "    'Zaanstad_unbalance': 30,\n",
    "}\n",
    "\n",
    "if len(dataset) < 10000:\n",
    "    max_depth = max_depths['Oosterhout_unbalance']\n",
    "else:\n",
    "    max_depth = max_depths['Zaanstad_unbalance']\n",
    "\n",
    "# Generalizability cross datasets\n",
    "dataset_name = 'Oosterhout' if len(dataset) < 10000 else 'Zaanstad'\n",
    "print(f'Dataset: {dataset_name}')\n",
    "\n",
    "data_oosterhout = gdf_oosterhout\n",
    "data_zaanstad = gdf_zaanstad\n",
    "\n",
    "if baseline:\n",
    "    data_oosterhout = data_oosterhout.drop(columns=['BKK'])\n",
    "    data_zaanstad = data_zaanstad.drop(columns=['BKK'])\n",
    "else:\n",
    "    # Define the mapping for ordinal encoding\n",
    "    bkk_mapping = {'AW_2000': 1, 'Wonen': 2, 'Industrie': 3}\n",
    "\n",
    "    # Apply the mapping to the BKK column\n",
    "    data_oosterhout.replace({\"BKK\": bkk_mapping}, inplace=True)\n",
    "    data_oosterhout = data_oosterhout[data_oosterhout['BKK'] != 'Onbekend'].dropna()\n",
    "    \n",
    "    data_zaanstad.replace({\"BKK\": bkk_mapping}, inplace=True)\n",
    "    data_zaanstad = data_zaanstad[data_zaanstad['BKK'] != 'Onbekend'].dropna()\n",
    "\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data_oosterhout['TOETS_WBB'] = label_encoder.fit_transform(data_oosterhout['TOETS_WBB'])\n",
    "data_zaanstad['TOETS_WBB'] = label_encoder.fit_transform(data_zaanstad['TOETS_WBB'])\n",
    "\n",
    "# Define features and target variable\n",
    "X_oosterhout = data_oosterhout.drop(columns=['TOETS_WBB'])\n",
    "y_oosterhout = data_oosterhout['TOETS_WBB']\n",
    "X_zaanstad = data_zaanstad.drop(columns=['TOETS_WBB'])\n",
    "y_zaanstad = data_zaanstad['TOETS_WBB']\n",
    "\n",
    "# Columns to normalize\n",
    "columns_to_normalize = ['days_since_ref', 'X', 'Y']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_oosterhout[columns_to_normalize] = scaler.fit_transform(X_oosterhout[columns_to_normalize])\n",
    "X_zaanstad[columns_to_normalize] = scaler.transform(X_zaanstad[columns_to_normalize])\n",
    "\n",
    "# Initialize RandomForest model\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model on one dataset and evaluate on the other\n",
    "if dataset_name == 'Zaanstad':\n",
    "    rf_model.fit(X_zaanstad, y_zaanstad)\n",
    "    y_pred = rf_model.predict(X_oosterhout)\n",
    "    y_true = y_oosterhout\n",
    "else:\n",
    "    rf_model.fit(X_oosterhout, y_oosterhout)\n",
    "    y_pred = rf_model.predict(X_zaanstad)\n",
    "    y_true = y_zaanstad\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "test_precision = precision_score(y_true, y_pred)\n",
    "test_recall = recall_score(y_true, y_pred)\n",
    "test_f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print the test set results\n",
    "print(\"\\nTest set results:\")\n",
    "print(\"Accuracy: \", round(test_accuracy, 5))\n",
    "print(\"Recall: \", round(test_recall, 5))\n",
    "print(\"Precision: \", round(test_precision, 5))\n",
    "print(\"F1-score: \", round(test_f1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592f12f",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "gdf_zaanstad = gpd.read_file(\"../Data/dataset_zaanstad.gpkg\", layer=\"polluted_points\")\n",
    "gdf_oosterhout = gpd.read_file(\"../Data/dataset_oosterhout.gpkg\", layer=\"polluted_points\")\n",
    "\n",
    "# Exclude BOORPUNT_ID and geometry\n",
    "gdf_zaanstad = gdf_zaanstad.drop(columns=['BOORPUNT_ID', 'geometry'])\n",
    "gdf_oosterhout = gdf_oosterhout.drop(columns=['BOORPUNT_ID', 'geometry'])\n",
    "\n",
    "# Rename columns to English for the plot\n",
    "gdf_zaanstad = gdf_zaanstad.rename(columns={\"gewaspercelen\": \"Agricultural land\", \"oppervlaktewater\": \"Surface water\", \"wegen\":\"Roads\", \"spoorwegen\":\"Railroad\", \"industry\":\"Industry\", \"days_since_ref\":\"Date\"})\n",
    "gdf_oosterhout = gdf_oosterhout.rename(columns={\"gewaspercelen\": \"Agricultural land\", \"oppervlaktewater\": \"Surface water\", \"wegen\":\"Roads\", \"spoorwegen\":\"Railroad\", \"industry\":\"Industry\", \"days_since_ref\":\"Date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c10488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute learning curves for recall\n",
    "def compute_recall_learning_curves(X_train, y_train, X_val, y_val, max_depth, step_size=100):\n",
    "    train_sizes = np.arange(step_size, len(X_train), step_size)\n",
    "    val_recall = []\n",
    "\n",
    "    for size in train_sizes:\n",
    "        X_train_subset = X_train[:size]\n",
    "        y_train_subset = y_train[:size]\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=200, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_recall.append(recall_score(y_val, y_val_pred, average='binary'))\n",
    "\n",
    "    return train_sizes, val_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91720cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "def preprocess_data(data, use_bkk):\n",
    "    if not use_bkk:\n",
    "        data = data.drop(columns=['BKK'])\n",
    "    else:\n",
    "        bkk_mapping = {'AW_2000': 1, 'Wonen': 2, 'Industrie': 3}\n",
    "        data.replace({\"BKK\": bkk_mapping}, inplace=True)\n",
    "        data = data[data['BKK'] != 'Onbekend'].dropna()\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['TOETS_WBB'] = label_encoder.fit_transform(data['TOETS_WBB'])\n",
    "\n",
    "    X = data.drop(columns=['TOETS_WBB'])\n",
    "    y = data['TOETS_WBB']\n",
    "\n",
    "    # Columns to normalize\n",
    "    columns_to_normalize = ['Date', 'X', 'Y']\n",
    "    scaler = StandardScaler()\n",
    "    X[columns_to_normalize] = scaler.fit_transform(X[columns_to_normalize])\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess datasets\n",
    "X_train_oost, X_val_oost, y_train_oost, y_val_oost = preprocess_data(gdf_oosterhout, use_bkk=False)\n",
    "X_train_oost_bkk, X_val_oost_bkk, y_train_oost_bkk, y_val_oost_bkk = preprocess_data(gdf_oosterhout, use_bkk=True)\n",
    "X_train_zaan, X_val_zaan, y_train_zaan, y_val_zaan = preprocess_data(gdf_zaanstad, use_bkk=False)\n",
    "X_train_zaan_bkk, X_val_zaan_bkk, y_train_zaan_bkk, y_val_zaan_bkk = preprocess_data(gdf_zaanstad, use_bkk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute learning curves\n",
    "train_sizes_oost, val_recall_oost = compute_recall_learning_curves(X_train_oost, y_train_oost, X_val_oost, y_val_oost, 20)\n",
    "train_sizes_oost_bkk, val_recall_oost_bkk = compute_recall_learning_curves(X_train_oost_bkk, y_train_oost_bkk, X_val_oost_bkk, y_val_oost_bkk, 20)\n",
    "train_sizes_zaan, val_recall_zaan = compute_recall_learning_curves(X_train_zaan, y_train_zaan, X_val_zaan, y_val_zaan, 30)\n",
    "train_sizes_zaan_bkk, val_recall_zaan_bkk = compute_recall_learning_curves(X_train_zaan_bkk, y_train_zaan_bkk, X_val_zaan_bkk, y_val_zaan_bkk, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the font size for the entire plot\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Define a function to plot and save each subplot with custom tick font size\n",
    "def plot_and_save(train_sizes1, val_recall1, train_sizes2, val_recall2, title, xlabel, ylabel, labels, filename, tick_fontsize=12):\n",
    "    plt.figure(figsize=(7.5, 4))  # Adjust the size as needed\n",
    "    plt.plot(train_sizes1, val_recall1, label=labels[0])\n",
    "    plt.plot(train_sizes2, val_recall2, label=labels[1])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Plot and save Oosterhout Recall\n",
    "plot_and_save(\n",
    "    train_sizes_oost, \n",
    "    val_recall_oost, \n",
    "    train_sizes_oost_bkk, \n",
    "    val_recall_oost_bkk, \n",
    "    'Oosterhout Recall', \n",
    "    'Training Size', \n",
    "    'Recall', \n",
    "    ['Oosterhout without BKK', 'Oosterhout with BKK'], \n",
    "    'oosterhout_recall.png',\n",
    "    tick_fontsize=12  # Adjust the tick font size as needed\n",
    ")\n",
    "\n",
    "# Plot and save Zaanstad Recall\n",
    "plot_and_save(\n",
    "    train_sizes_zaan, \n",
    "    val_recall_zaan, \n",
    "    train_sizes_zaan_bkk, \n",
    "    val_recall_zaan_bkk, \n",
    "    'Zaanstad Recall', \n",
    "    'Training Size', \n",
    "    'Recall', \n",
    "    ['Zaanstad without BKK', 'Zaanstad with BKK'], \n",
    "    'zaanstad_recall.png',\n",
    "    tick_fontsize=12  # Adjust the tick font size as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799bc15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
