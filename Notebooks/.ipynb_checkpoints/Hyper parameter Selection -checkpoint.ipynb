{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bafa07f",
   "metadata": {},
   "source": [
    "# GirdSearch Analysis\n",
    "In the third cell a selection can be made for which dataset the analysis should be run and if the dataset should be balanced or unbalanced, afterwards the additional code can be run to show the graph corresponding to the chosen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a23829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "gdf_zaanstad = gpd.read_file(\"../Data/dataset_zaanstad.gpkg\", layer=\"polluted_points\")\n",
    "gdf_oosterhout = gpd.read_file(\"../Data/dataset_oosterhout.gpkg\", layer=\"polluted_points\")\n",
    "\n",
    "# Exclude BOORPUNT_ID\n",
    "gdf_zaanstad = gdf_zaanstad.drop(columns=['BOORPUNT_ID'])\n",
    "gdf_oosterhout = gdf_oosterhout.drop(columns=['BOORPUNT_ID'])\n",
    "\n",
    "# Exclude geopandas geometry as variable\n",
    "gdf_zaanstad = gdf_zaanstad.drop(columns=['geometry'])\n",
    "gdf_oosterhout = gdf_oosterhout.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = gdf_zaanstad\n",
    "# dataset = gdf_oosterhout\n",
    "\n",
    "# Balanced vs not balanced\n",
    "balanced = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude BKK\n",
    "gdf_gridsearch = dataset.drop(columns=['BKK'])\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "gdf_gridsearch['TOETS_WBB'] = label_encoder.fit_transform(gdf_gridsearch['TOETS_WBB'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = gdf_gridsearch.drop(columns=['TOETS_WBB'])\n",
    "y = gdf_gridsearch['TOETS_WBB']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Columns to normalize\n",
    "columns_to_normalize = ['days_since_ref', 'X', 'Y']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "# Set params for GridSearch\n",
    "params = {\n",
    "    'max_depth': [10, 20, 30, 50, None],\n",
    "}\n",
    "\n",
    "# Initialize lists to hold the metric values\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "test_accuracies = []\n",
    "test_precisions = []\n",
    "test_recalls = []\n",
    "test_f1s = []\n",
    "\n",
    "# Iterate through each set of parameters\n",
    "for max_depth in params['max_depth']:\n",
    "    # Initialize the model with the current parameters\n",
    "    if balanced:\n",
    "        model = RandomForestClassifier(n_estimators=200, max_depth=max_depth, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "    else:\n",
    "        model = RandomForestClassifier(n_estimators=200, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "        \n",
    "    # Perform cross-validation and calculate metrics\n",
    "    scores = cross_validate(model, X_train, y_train, cv=10, scoring=['accuracy', 'precision', 'recall', 'f1'], return_train_score=True)\n",
    "    \n",
    "    # Append metrics to the lists\n",
    "    accuracies.append(scores['test_accuracy'].mean())\n",
    "    precisions.append(scores['test_precision'].mean())\n",
    "    recalls.append(scores['test_recall'].mean())\n",
    "    f1s.append(scores['test_recall'].mean())\n",
    "    \n",
    "    # Train the model on the entire training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append test set metrics to the lists\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    test_precisions.append(test_precision)\n",
    "    test_recalls.append(test_recall)\n",
    "    test_f1s.append(test_f1)\n",
    "\n",
    "# Convert the lists to arrays for easier manipulation\n",
    "accuracies = np.array(accuracies)\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "f1s = np.array(f1s)\n",
    "test_accuracies = np.array(test_accuracies)\n",
    "test_precisions = np.array(test_precisions)\n",
    "test_recalls = np.array(test_recalls)\n",
    "test_f1s = np.array(test_f1s)\n",
    "\n",
    "# Create a dataframe for easier plotting\n",
    "results_df = pd.DataFrame({\n",
    "    'max_depth': [str(p) for p in params['max_depth']],\n",
    "    'train_accuracy': accuracies,\n",
    "    'train_precision': precisions,\n",
    "    'train_recall': recalls,\n",
    "    'train_f1' : f1s,\n",
    "    'test_accuracy': test_accuracies,\n",
    "    'test_precision': test_precisions,\n",
    "    'test_recall': test_recalls,\n",
    "    'test_f1': test_f1s\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the font size\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 4, 1)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 1])\n",
    "plt.plot(results_df['max_depth'], results_df['train_accuracy'], marker='o', label='Cross Validation')\n",
    "plt.plot(results_df['max_depth'], results_df['test_accuracy'], marker='o', color='red', label='Test Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Parameter Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Plot precision\n",
    "plt.subplot(1, 4, 2)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 1])\n",
    "plt.plot(results_df['max_depth'], results_df['train_precision'], marker='o', label='Cross Validation')\n",
    "plt.plot(results_df['max_depth'], results_df['test_precision'], marker='o', color='red', label='Test Validation')\n",
    "plt.title('Precision')\n",
    "plt.xlabel('Parameter Max Depth')\n",
    "plt.ylabel('Precision')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Plot recall\n",
    "plt.subplot(1, 4, 3)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 1])\n",
    "plt.plot(results_df['max_depth'], results_df['train_recall'], marker='o', label='Cross Validation')\n",
    "plt.plot(results_df['max_depth'], results_df['test_recall'], marker='o', color='red', label='Test Validation')\n",
    "plt.title('Recall')\n",
    "plt.xlabel('Parameter Max Depth')\n",
    "plt.ylabel('Recall')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Plot recall\n",
    "plt.subplot(1, 4, 4)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 1])\n",
    "plt.plot(results_df['max_depth'], results_df['train_f1'], marker='o', label='Cross Validation')\n",
    "plt.plot(results_df['max_depth'], results_df['test_f1'], marker='o', color='red', label='Test Validation')\n",
    "plt.title('F1-score')\n",
    "plt.xlabel('Parameter Max Depth')\n",
    "plt.ylabel('F1-score')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "# Add a general title for all subplots\n",
    "if len(dataset) > 10000:\n",
    "    gemeenten = 'Dataset Zaanstad'\n",
    "else:\n",
    "    gemeenten = 'Dataset Oosterhout'\n",
    "    \n",
    "if balanced:\n",
    "    balance = ' balanced'\n",
    "else:\n",
    "    balance = ' not balanced'\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{gemeenten}{balance}.png', facecolor='white')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
